{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python368jvsc74a57bd060aa7568c9db8113868ebef0220b161e96389b06f6ba9eb98d46b6b0f2cf6a72",
   "display_name": "Python 3.6.8 64-bit ('benchmark': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'note_processing'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f2456f71e3f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnote_processing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheuristic_tokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msent_tokenize_rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'note_processing'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import spacy\n",
    "import re\n",
    "import time\n",
    "import scispacy\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from note_processing.heuristic_tokenize import sent_tokenize_rules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT_DIR = '/mnt/data01/mimic-3/benchmark-small/test/345' #this path will contain tokenized notes. This dir will be the input dir for create_pretrain_data.sh\n",
    "\n",
    "#this is the path to mimic data if you're reading from a csv. Else uncomment the code to read from database below\n",
    "MIMIC_NOTES_PATHS = ['/mnt/data01/mimic-3/benchmark-small/test',\n",
    "                     '/mnt/data01/mimic-3/benchmark-small/train']  \n",
    "\n",
    "WORKERS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Load note files: 100%|██████████| 37/37 [00:00<00:00, 291.64it/s]\n",
      "Total note files: 43\n",
      "Total unprocessed files: 37\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              Hours CATEGORY            DESCRIPTION  \\\n",
       "count   1051.000000     1051                   1051   \n",
       "unique          NaN       10                     60   \n",
       "top             NaN  Nursing  Nursing Progress Note   \n",
       "freq            NaN      481                    376   \n",
       "mean      96.352609      NaN                    NaN   \n",
       "std      126.598239      NaN                    NaN   \n",
       "min        0.201111      NaN                    NaN   \n",
       "25%       14.525833      NaN                    NaN   \n",
       "50%       36.261111      NaN                    NaN   \n",
       "75%      121.352361      NaN                    NaN   \n",
       "max      545.461667      NaN                    NaN   \n",
       "\n",
       "                                                     TEXT  \\\n",
       "count                                                1051   \n",
       "unique                                                981   \n",
       "top     Chief Complaint:\\n   24 Hour Events:\\n   - SBP...   \n",
       "freq                                                    5   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                                 filename  \n",
       "count                                                1051  \n",
       "unique                                                 35  \n",
       "top     /mnt/data01/mimic-3/benchmark-small/train/124/...  \n",
       "freq                                                  226  \n",
       "mean                                                  NaN  \n",
       "std                                                   NaN  \n",
       "min                                                   NaN  \n",
       "25%                                                   NaN  \n",
       "50%                                                   NaN  \n",
       "75%                                                   NaN  \n",
       "max                                                   NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Hours</th>\n      <th>CATEGORY</th>\n      <th>DESCRIPTION</th>\n      <th>TEXT</th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1051.000000</td>\n      <td>1051</td>\n      <td>1051</td>\n      <td>1051</td>\n      <td>1051</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>10</td>\n      <td>60</td>\n      <td>981</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>Nursing</td>\n      <td>Nursing Progress Note</td>\n      <td>Chief Complaint:\\n   24 Hour Events:\\n   - SBP...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/train/124/...</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>481</td>\n      <td>376</td>\n      <td>5</td>\n      <td>226</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>96.352609</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>126.598239</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.201111</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>14.525833</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>36.261111</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>121.352361</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>545.461667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "all_files = []\n",
    "\n",
    "for path in MIMIC_NOTES_PATHS:\n",
    "    files = glob.glob(path + \"/*/*_notes.csv\")\n",
    "    all_files += files\n",
    "\n",
    "print(\"\\nTotal note files: \" + str(len(all_files)))\n",
    "all_files = [f for f in all_files if not os.path.exists(f[:-4] + '_sent.csv')]\n",
    "print(\"Total unprocessed files: \" + str(len(all_files)))\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in tqdm(all_files, desc=\"Load note files\"):\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    df[\"filename\"] = filename\n",
    "    li.append(df)\n",
    "\n",
    "notes = pd.concat(li, axis=0, ignore_index=True)\n",
    "notes.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Hours       CATEGORY                 DESCRIPTION  \\\n",
       "0  0.201111      Radiology         CHEST (PORTABLE AP)   \n",
       "1  1.034444      Radiology  CHEST PORT. LINE PLACEMENT   \n",
       "2  1.967778      Radiology  CHEST PORT. LINE PLACEMENT   \n",
       "3  7.351111  Nursing/other                      Report   \n",
       "4  7.584444  Nursing/other                      Report   \n",
       "\n",
       "                                                TEXT  \\\n",
       "0  [**2169-5-21**] 10:17 PM\\n CHEST (PORTABLE AP)...   \n",
       "1  [**2169-5-21**] 11:07 PM\\n CHEST PORT. LINE PL...   \n",
       "2  [**2169-5-22**] 12:03 AM\\n CHEST PORT. LINE PL...   \n",
       "3  Respiratory CAre\\nPt received from ED intubate...   \n",
       "4  0000-0700 NPN\\nPt. admitted via ER from [**Hos...   \n",
       "\n",
       "                                            filename  \n",
       "0  /mnt/data01/mimic-3/benchmark-small/test/345/e...  \n",
       "1  /mnt/data01/mimic-3/benchmark-small/test/345/e...  \n",
       "2  /mnt/data01/mimic-3/benchmark-small/test/345/e...  \n",
       "3  /mnt/data01/mimic-3/benchmark-small/test/345/e...  \n",
       "4  /mnt/data01/mimic-3/benchmark-small/test/345/e...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Hours</th>\n      <th>CATEGORY</th>\n      <th>DESCRIPTION</th>\n      <th>TEXT</th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.201111</td>\n      <td>Radiology</td>\n      <td>CHEST (PORTABLE AP)</td>\n      <td>[**2169-5-21**] 10:17 PM\\n CHEST (PORTABLE AP)...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/test/345/e...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.034444</td>\n      <td>Radiology</td>\n      <td>CHEST PORT. LINE PLACEMENT</td>\n      <td>[**2169-5-21**] 11:07 PM\\n CHEST PORT. LINE PL...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/test/345/e...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.967778</td>\n      <td>Radiology</td>\n      <td>CHEST PORT. LINE PLACEMENT</td>\n      <td>[**2169-5-22**] 12:03 AM\\n CHEST PORT. LINE PL...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/test/345/e...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.351111</td>\n      <td>Nursing/other</td>\n      <td>Report</td>\n      <td>Respiratory CAre\\nPt received from ED intubate...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/test/345/e...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.584444</td>\n      <td>Nursing/other</td>\n      <td>Report</td>\n      <td>0000-0700 NPN\\nPt. admitted via ER from [**Hos...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/test/345/e...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "notes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               Hours DESCRIPTION  TEXT filename\n",
       "               count       count count    count\n",
       "CATEGORY                                       \n",
       "General           23          23    23       23\n",
       "Nursing          481         481   481      481\n",
       "Nursing/other     11          11    11       11\n",
       "Nutrition         13          13    13       13\n",
       "Pharmacy           2           2     2        2\n",
       "Physician        329         329   329      329\n",
       "Radiology        108         108   108      108\n",
       "Rehab Services     8           8     8        8\n",
       "Respiratory       75          75    75       75\n",
       "Social Work        1           1     1        1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>Hours</th>\n      <th>DESCRIPTION</th>\n      <th>TEXT</th>\n      <th>filename</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>count</th>\n      <th>count</th>\n      <th>count</th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>CATEGORY</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>General</th>\n      <td>23</td>\n      <td>23</td>\n      <td>23</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>Nursing</th>\n      <td>481</td>\n      <td>481</td>\n      <td>481</td>\n      <td>481</td>\n    </tr>\n    <tr>\n      <th>Nursing/other</th>\n      <td>11</td>\n      <td>11</td>\n      <td>11</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>Nutrition</th>\n      <td>13</td>\n      <td>13</td>\n      <td>13</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>Pharmacy</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Physician</th>\n      <td>329</td>\n      <td>329</td>\n      <td>329</td>\n      <td>329</td>\n    </tr>\n    <tr>\n      <th>Radiology</th>\n      <td>108</td>\n      <td>108</td>\n      <td>108</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>Rehab Services</th>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>Respiratory</th>\n      <td>75</td>\n      <td>75</td>\n      <td>75</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>Social Work</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "notes.groupby(\"CATEGORY\").agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aflanders:\n",
    "# This code will split the notes into natural sentence boundaries separated by \\n\n",
    "# which can then be fed into sentence embedding models such as BIO-ClinicalBert or \n",
    "# BioSentVec\n",
    "#\n",
    "# This frame and the next are largly from format_mimic_for_BERT.py in EmilyAlsentzer/clinicalBERT\n",
    "# I have updated the code to work with spacy 3.0 and made some other changes\n",
    "#\n",
    "# Example:\n",
    "# THis is a \n",
    "# single \n",
    "# sentence. and another sentence.\n",
    "\n",
    "# THis is a single sentence.\\n\n",
    "# and another sentence.\\n\n",
    "\n",
    "from spacy.language import Language\n",
    "\n",
    "#setting sentence boundaries\n",
    "@Language.component('sbd_component')\n",
    "def sbd_component(doc):\n",
    "    for i, token in enumerate(doc[:-2]):\n",
    "        # define sentence start if period + titlecase token\n",
    "        if token.text == '.' and doc[i+1].is_title:\n",
    "            doc[i+1].sent_start = True\n",
    "        if token.text == '-' and doc[i+1].text != '-':\n",
    "            doc[i+1].sent_start = True\n",
    "    return doc\n",
    "\n",
    "#convert de-identification text into one token\n",
    "# aflanders: no need to pass in the next separate, is available in processed_text\n",
    "# def fix_deid_tokens(text, processed_text):\n",
    "def fix_deid_tokens(doc):\n",
    "    deid_regex  = r\"\\[\\*\\*.{0,15}.*?\\*\\*\\]\" \n",
    "\n",
    "    indexes = [m.span() for m in re.finditer(deid_regex, doc.text, flags=re.IGNORECASE)]\n",
    "\n",
    "    for start,end in indexes:\n",
    "        # processed_text.merge(start_idx=start,end_idx=end)\n",
    "        # aflanders: Make compatible with latest version fo spacy\n",
    "        try:\n",
    "            span = doc.char_span(start, end)\n",
    "            if span is not None:\n",
    "                with doc.retokenize() as retokenizer:\n",
    "                    # retokenizer.merge(processed_text[start:end+1])\n",
    "                    retokenizer.merge(span)\n",
    "        except:\n",
    "            print(f'Error with: {text}')\n",
    "                \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_section(section, note, processed_sections):\n",
    "    # perform spacy processing on section\n",
    "    processed_section = nlp(section['sections'])\n",
    "    # processed_section = fix_deid_tokens(section['sections'], processed_section)\n",
    "    processed_section = fix_deid_tokens(processed_section)\n",
    "    processed_sections.append(processed_section)\n",
    "\n",
    "def process_note_helper(note):\n",
    "    # split note into sections\n",
    "    note_sections = sent_tokenize_rules(note)\n",
    "    processed_sections = []\n",
    "    section_frame = pd.DataFrame({'sections':note_sections})\n",
    "    section_frame.apply(process_section, args=(note,processed_sections,), axis=1)\n",
    "    return(processed_sections)\n",
    "\n",
    "def process_text(sent, note):\n",
    "    sent_text = sent['sents'].text\n",
    "    if len(sent_text) > 0 and sent_text.strip() != '\\n' and len(sent_text.split()) > 1:\n",
    "        if '\\n' in sent_text:\n",
    "            sent_text = sent_text.replace('\\n', ' ')\n",
    "        note['TEXT'] += sent_text + '\\n'  \n",
    "\n",
    "def get_sentences(processed_section, note):\n",
    "    # get sentences from spacy processing\n",
    "    sent_frame = pd.DataFrame({'sents': list(processed_section['sections'].sents)})\n",
    "    sent_frame.apply(process_text, args=(note,), axis=1)\n",
    "\n",
    "def process_note(note):\n",
    "    try:\n",
    "        note_text = note['TEXT'] #unicode(note['text'])\n",
    "        note['TEXT'] = ''\n",
    "        processed_sections = process_note_helper(note_text)\n",
    "        ps = {'sections': processed_sections}\n",
    "        ps = pd.DataFrame(ps)\n",
    "        ps.apply(get_sentences, args=(note,), axis=1)\n",
    "        return note \n",
    "    except Exception as e:\n",
    "        # pass\n",
    "        print ('error processing note', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Begin reading notes\nNumber of notes: 11\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function __main__.sbd_component>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# %time\n",
    "\n",
    "#category = [\"Nursing\", \"Nursing/other\", 'General', 'Physician ']  # or None\n",
    "category = [\"Nursing/other\"]  # or None\n",
    "\n",
    "# start = time.time()\n",
    "# tqdm.pandas()\n",
    "\n",
    "print('Begin reading notes')\n",
    "\n",
    "if category != None:\n",
    "    notes = notes[notes['CATEGORY'].isin(category)]\n",
    "print('Number of notes: %d' %len(notes.index))\n",
    "# notes['ind'] = list(range(len(notes.index)))\n",
    "\n",
    "nlp = spacy.load('en_core_sci_md', disable=['tagger','ner', 'lemmatizer'])\n",
    "nlp.add_pipe('sbd_component', before='parser')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "filenames = list(notes[\"filename\"].unique().tolist())\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO: Pandarallel will run on 5 workers.\nINFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3), Label(value='0 / 3'))), HBox(c…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1971b6d1a97b4556bf7fe4e6aa014069"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "formatted_notes = notes.parallel_apply(process_note, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Hours       CATEGORY DESCRIPTION  \\\n",
       "3   7.351111  Nursing/other      Report   \n",
       "4   7.584444  Nursing/other      Report   \n",
       "6  20.067778  Nursing/other      Report   \n",
       "\n",
       "                                                TEXT  \\\n",
       "3  Respiratory CAre Pt received from ED intubated...   \n",
       "4  0700 NPN Pt. admitted via ER\\nfrom [**Hospital...   \n",
       "6  BS CTAB, no change with MDI's.\\nSuctioned for ...   \n",
       "\n",
       "                                            filename  \n",
       "3  /mnt/data01/mimic-3/benchmark-small/test/345/e...  \n",
       "4  /mnt/data01/mimic-3/benchmark-small/test/345/e...  \n",
       "6  /mnt/data01/mimic-3/benchmark-small/test/345/e...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Hours</th>\n      <th>CATEGORY</th>\n      <th>DESCRIPTION</th>\n      <th>TEXT</th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>7.351111</td>\n      <td>Nursing/other</td>\n      <td>Report</td>\n      <td>Respiratory CAre Pt received from ED intubated...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/test/345/e...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.584444</td>\n      <td>Nursing/other</td>\n      <td>Report</td>\n      <td>0700 NPN Pt. admitted via ER\\nfrom [**Hospital...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/test/345/e...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>20.067778</td>\n      <td>Nursing/other</td>\n      <td>Report</td>\n      <td>BS CTAB, no change with MDI's.\\nSuctioned for ...</td>\n      <td>/mnt/data01/mimic-3/benchmark-small/test/345/e...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "formatted_notes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Writing note sentence files: 100%|██████████| 7/7 [00:00<00:00, 414.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Write out a new note files organized by sentence\n",
    "filenames = list(formatted_notes[\"filename\"].unique().tolist())\n",
    "for filename in tqdm(filenames, desc=\"Writing note sentence files\"):\n",
    "    df = formatted_notes[formatted_notes[\"filename\"] == filename][[\"Hours\", \"CATEGORY\", \"DESCRIPTION\", \"TEXT\"]]\n",
    "    df = df.set_index(\"Hours\")\n",
    "    write_file = filename.replace(\".csv\", \"_sent.csv\")\n",
    "    with open(write_file, \"w\") as f:\n",
    "        df.to_csv(f, index_label='Hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}