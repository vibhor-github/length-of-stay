{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sent2vec\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model successfully loaded\n"
     ]
    }
   ],
   "source": [
    "model_path = \"BioSentVec_PubMed_MIMICIII-bigram_d700.bin\"\n",
    "model = sent2vec.Sent2vecModel()\n",
    "try:\n",
    "    model.load_model(model_path)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "print('model successfully loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.158056</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>[**2128-5-12**]\\n7:27 AM  CHEST (PORTABLE AP) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.158056</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>[**2128-5-12**]\\n7:27 AM  CHEST (PORTABLE AP) ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Hours   CATEGORY          DESCRIPTION  \\\n",
       "0  16.158056  Radiology  CHEST (PORTABLE AP)   \n",
       "1  17.158056  Radiology  CHEST (PORTABLE AP)   \n",
       "\n",
       "                                                TEXT  \n",
       "0  [**2128-5-12**]\\n7:27 AM  CHEST (PORTABLE AP) ...  \n",
       "1  [**2128-5-12**]\\n7:27 AM  CHEST (PORTABLE AP) ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('episode1_notes_sent.csv')\n",
    "#print(df.TEXT)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.158056</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>[[-1.639137, 0.90079296, 0.1578581, -0.1033803...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.158056</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>[[-1.639137, 0.90079296, 0.1578581, -0.1033803...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Hours   CATEGORY          DESCRIPTION  \\\n",
       "0  16.158056  Radiology  CHEST (PORTABLE AP)   \n",
       "1  17.158056  Radiology  CHEST (PORTABLE AP)   \n",
       "\n",
       "                                                TEXT  \n",
       "0  [[-1.639137, 0.90079296, 0.1578581, -0.1033803...  \n",
       "1  [[-1.639137, 0.90079296, 0.1578581, -0.1033803...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#sentence = preprocess_sentence('Breast cancers with HER2 amplification have a higher risk of CNS metastasis and poorer prognosis.')\n",
    "# sentence ='Breast cancers with HER2 amplification have a higher risk of CNS metastasis and poorer prognosis.'\n",
    "# print(sentence)\n",
    "# sentence=model.embed_sentence(sentence)\n",
    "\n",
    "#def convert_to_list(df):\n",
    "    \n",
    "df.TEXT=df.TEXT.apply(model.embed_sentences)\n",
    "df.head()\n",
    "#print(df.TEXT[0].shape)\n",
    "# sentence= df.TEXT\n",
    "# print(type(sentence))\n",
    "# print(sentence.size)\n",
    "# #print(sentence)\n",
    "# for i in sentence:\n",
    "#     sen= i.split('\\n')\n",
    "#     sen=np.asarray(sen)\n",
    "#     #print(sen)\n",
    "#     print(type(sen))\n",
    "#     sentence=model.embed_sentences(sen)\n",
    "#     print(type(sentence))\n",
    "#     print(sentence.shape)\n",
    "# #df.TEXT = df.apply(model.embed_sentence)\n",
    "#print(df.TEXT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(968, 700)\n"
     ]
    }
   ],
   "source": [
    "print(df.TEXT[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "df2=pd.read_csv('episode1_notes_sent.csv')\n",
    "#print(df2.TEXT[0])\n",
    "df2.head()\n",
    "def convert_to_list(i):\n",
    "    sen= i.split('\\n')\n",
    "    sen=[x for x in sen if len(x)>=3]\n",
    "    sen=np.asarray(sen)\n",
    "    return(sen)\n",
    "df2.TEXT=df2.TEXT.apply(convert_to_list)\n",
    "print(df2.TEXT[0].shape)\n",
    "#print(df2.TEXT[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(20, 700)\n"
     ]
    }
   ],
   "source": [
    "print(type(df2.TEXT[0]))\n",
    "df2.TEXT=df2.TEXT.apply(model.embed_sentences)\n",
    "df2.head()\n",
    "print(df2.TEXT[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import pandas as pd\n",
    "\n",
    "class EpisodeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, obs1, obs2, los):\n",
    "        self.x1 = obs1\n",
    "        self.x2 = obs2\n",
    "        self.y = los\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x1[index], self.x2[index], self.y[index])\n",
    "        \n",
    "x1_train=torch.torch.rand(32,1,16)\n",
    "x2_train=torch.rand(32,1,16)\n",
    "Y_train= torch.randint(low=1, high=10, size=(32,1))\n",
    "train_dataset = EpisodeDataset(x1_train, x2_train, Y_train)\n",
    "x1_val=torch.rand(32,1,16)\n",
    "x2_val=torch.rand(32,1,16)\n",
    "Y_val= torch.randint(low=1, high=10, size=(32,1))\n",
    "val_dataset = EpisodeDataset(x1_val, x2_val, Y_val)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32,shuffle=True) \n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32,shuffle=True) \n",
    "# for data in train_dataset:\n",
    "#     print(data[0].shape, data[1].shape, data[2].shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpisiodeCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EpisiodeCNN, self).__init__()\n",
    "        #input shape 1x2x16\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=2, padding=1, stride = 1)\n",
    "        16-2*2*1\n",
    "        #output shape 16x3x17\n",
    "        #input shape  16x2x16\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=2, padding=1, stride = 1)\n",
    "        #output shape 32x4x18\n",
    "        #input shape  32x4x18\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        #output shape 32x2x9\n",
    "        #input shape 32x2x9\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=2, padding=1, stride = 1)\n",
    "        #output shape 64x3x10\n",
    "        self.fc1 = nn.Linear(64*3*10, 256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x1,x2):\n",
    "        #input is of shape (batch_size=32,1,16) if you did the dataloader right\n",
    "        x=torch.cat((x1, x2), axis=1)\n",
    "        #Expected x shape =2x16\n",
    "        x = x.unsqueeze(1)   #1x2x16\n",
    "#         print(\"input\", x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "#         print(\"conv1\", x.shape)\n",
    "        x = F.relu(self.conv2(x))\n",
    "#         print(\"conv2\", x.shape)\n",
    "        x = self.pool1(x)\n",
    "#         print(\"pool\",x.shape)\n",
    "        x = F.relu(self.conv3(x))\n",
    "#         print(\"conv3\", x.shape)\n",
    "        x = x.view(-1, 64 * 3 * 10)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "#         print(\"result\",x.shape)\n",
    "        return (x.double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 29.447703\n",
      "Epoch: 2 \tTraining Loss: 22.267662\n",
      "Epoch: 3 \tTraining Loss: 49.260070\n",
      "Epoch: 4 \tTraining Loss: 14.410657\n",
      "Epoch: 5 \tTraining Loss: 24.711397\n",
      "Epoch: 6 \tTraining Loss: 26.939988\n",
      "Epoch: 7 \tTraining Loss: 27.558329\n",
      "Epoch: 8 \tTraining Loss: 27.570424\n",
      "Epoch: 9 \tTraining Loss: 27.492579\n",
      "Epoch: 10 \tTraining Loss: 27.205755\n",
      "Epoch: 11 \tTraining Loss: 26.669560\n",
      "Epoch: 12 \tTraining Loss: 25.796866\n",
      "Epoch: 13 \tTraining Loss: 24.074563\n",
      "Epoch: 14 \tTraining Loss: 21.158574\n",
      "Epoch: 15 \tTraining Loss: 16.299120\n",
      "Epoch: 16 \tTraining Loss: 11.379762\n",
      "Epoch: 17 \tTraining Loss: 7.612090\n",
      "Epoch: 18 \tTraining Loss: 12.491028\n",
      "Epoch: 19 \tTraining Loss: 15.707476\n",
      "Epoch: 20 \tTraining Loss: 5.782828\n",
      "Epoch: 21 \tTraining Loss: 8.207853\n",
      "Epoch: 22 \tTraining Loss: 10.845910\n",
      "Epoch: 23 \tTraining Loss: 9.600374\n",
      "Epoch: 24 \tTraining Loss: 11.293599\n",
      "Epoch: 25 \tTraining Loss: 9.601344\n",
      "Epoch: 26 \tTraining Loss: 6.897955\n",
      "Epoch: 27 \tTraining Loss: 6.679342\n",
      "Epoch: 28 \tTraining Loss: 9.437575\n",
      "Epoch: 29 \tTraining Loss: 7.185403\n",
      "Epoch: 30 \tTraining Loss: 7.558151\n",
      "Epoch: 31 \tTraining Loss: 6.116323\n",
      "Epoch: 32 \tTraining Loss: 6.038992\n",
      "Epoch: 33 \tTraining Loss: 6.126032\n",
      "Epoch: 34 \tTraining Loss: 8.703057\n",
      "Epoch: 35 \tTraining Loss: 6.795711\n",
      "Epoch: 36 \tTraining Loss: 7.022884\n",
      "Epoch: 37 \tTraining Loss: 7.114982\n",
      "Epoch: 38 \tTraining Loss: 5.732339\n",
      "Epoch: 39 \tTraining Loss: 6.869682\n",
      "Epoch: 40 \tTraining Loss: 7.190597\n",
      "Epoch: 41 \tTraining Loss: 6.019013\n",
      "Epoch: 42 \tTraining Loss: 7.061446\n",
      "Epoch: 43 \tTraining Loss: 7.202576\n",
      "Epoch: 44 \tTraining Loss: 6.164524\n",
      "Epoch: 45 \tTraining Loss: 6.776896\n",
      "Epoch: 46 \tTraining Loss: 6.695433\n",
      "Epoch: 47 \tTraining Loss: 5.978913\n",
      "Epoch: 48 \tTraining Loss: 6.656785\n",
      "Epoch: 49 \tTraining Loss: 6.011339\n",
      "Epoch: 50 \tTraining Loss: 7.782238\n",
      "Epoch: 51 \tTraining Loss: 5.892756\n",
      "Epoch: 52 \tTraining Loss: 4.768535\n",
      "Epoch: 53 \tTraining Loss: 7.989659\n",
      "Epoch: 54 \tTraining Loss: 6.515736\n",
      "Epoch: 55 \tTraining Loss: 6.010253\n",
      "Epoch: 56 \tTraining Loss: 6.242497\n",
      "Epoch: 57 \tTraining Loss: 6.866676\n",
      "Epoch: 58 \tTraining Loss: 5.258388\n",
      "Epoch: 59 \tTraining Loss: 6.499273\n",
      "Epoch: 60 \tTraining Loss: 5.971367\n",
      "Epoch: 61 \tTraining Loss: 5.890319\n",
      "Epoch: 62 \tTraining Loss: 5.570795\n",
      "Epoch: 63 \tTraining Loss: 7.048600\n",
      "Epoch: 64 \tTraining Loss: 6.271475\n",
      "Epoch: 65 \tTraining Loss: 6.797173\n",
      "Epoch: 66 \tTraining Loss: 6.468277\n",
      "Epoch: 67 \tTraining Loss: 6.959146\n",
      "Epoch: 68 \tTraining Loss: 6.129159\n",
      "Epoch: 69 \tTraining Loss: 6.357671\n",
      "Epoch: 70 \tTraining Loss: 4.474965\n",
      "Epoch: 71 \tTraining Loss: 5.318076\n",
      "Epoch: 72 \tTraining Loss: 5.890044\n",
      "Epoch: 73 \tTraining Loss: 6.100625\n",
      "Epoch: 74 \tTraining Loss: 4.988125\n",
      "Epoch: 75 \tTraining Loss: 6.958573\n",
      "Epoch: 76 \tTraining Loss: 6.900943\n",
      "Epoch: 77 \tTraining Loss: 6.688291\n",
      "Epoch: 78 \tTraining Loss: 7.034130\n",
      "Epoch: 79 \tTraining Loss: 5.214737\n",
      "Epoch: 80 \tTraining Loss: 6.078071\n",
      "Epoch: 81 \tTraining Loss: 4.737921\n",
      "Epoch: 82 \tTraining Loss: 4.998772\n",
      "Epoch: 83 \tTraining Loss: 5.403435\n",
      "Epoch: 84 \tTraining Loss: 5.327224\n",
      "Epoch: 85 \tTraining Loss: 5.811053\n",
      "Epoch: 86 \tTraining Loss: 6.209711\n",
      "Epoch: 87 \tTraining Loss: 6.118648\n",
      "Epoch: 88 \tTraining Loss: 4.458421\n",
      "Epoch: 89 \tTraining Loss: 5.194427\n",
      "Epoch: 90 \tTraining Loss: 4.657574\n",
      "Epoch: 91 \tTraining Loss: 5.906137\n",
      "Epoch: 92 \tTraining Loss: 5.106377\n",
      "Epoch: 93 \tTraining Loss: 4.023490\n",
      "Epoch: 94 \tTraining Loss: 3.921272\n",
      "Epoch: 95 \tTraining Loss: 3.418387\n",
      "Epoch: 96 \tTraining Loss: 4.418430\n",
      "Epoch: 97 \tTraining Loss: 4.438843\n",
      "Epoch: 98 \tTraining Loss: 4.501542\n",
      "Epoch: 99 \tTraining Loss: 3.715208\n",
      "Epoch: 100 \tTraining Loss: 3.862421\n"
     ]
    }
   ],
   "source": [
    "model = EpisiodeCNN()\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr =learning_rate )\n",
    "\n",
    "def train(model, train_loader, n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x1,x2, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x1,x2)\n",
    "#             print(\"y sizes\", y_hat.shape, y.shape)\n",
    "            loss = criterion(y_hat, y.double())\n",
    "#             print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_loss = train_loss / len(train_loader)\n",
    "            print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "\n",
    "    \n",
    "# number of epochs to train the model\n",
    "n_epochs = 100\n",
    "train(model, train_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
